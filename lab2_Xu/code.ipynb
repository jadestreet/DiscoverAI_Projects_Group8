{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Custom Environment for Reinforcement Learning**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below is taken from Nicholas Renotte's tutorial on how to create Custom environments for reinforcement learning. [Tutorial](https://youtu.be/Mut_u40Sqz4?t=8940), [code on github](https://github.com/nicknochnack/ReinforcementLearningCourse/blob/main/Project%203%20-%20Custom%20Environment.ipynb).\n",
                "\n",
                "You are encouraged to visit the links above and check out the full code. In this lab, you will practice training a model."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**About the problem**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The task is to build an agent that regulates the shower temperature to give the best shower possible every time.\n",
                "\n",
                "Based the activity of other people in the building, the temperature fluctuates randomly. Assuming that our optimal temperature is between 37 and 39 degrees, we want to train an agent to **automatically respond to changes in temperature** and **get it back within the preferred range**.\n",
                "\n",
                "Note that the agent does not know the preffered range ahead of time, and should instead learn the types of adjustments it can make to get a reward."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Import libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "#0 packages\n",
                "import os\n",
                "# Avoid reinstalling packages that are available on edstem\n",
                "if not os.getenv(\"ED_COURSE_ID\"):\n",
                "    !pip install tensorflow stable_baselines3 torch collections gym box2d-py --user\n",
                "    #6 packages\n",
                "\n",
                "#0.1 Import gym libraries\n",
                "import gym \n",
                "from gym import Env # the supperclass to build our own environment\n",
                "# All different types of spaces available in Gym\n",
                "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
                "\n",
                "#0.2 Import helpers\n",
                "import numpy as np\n",
                "import random\n",
                "\n",
                "#0.3 Import stable bbaselines libraries\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.vec_env import DummyVecEnv\n",
                "from stable_baselines3.common.evaluation import evaluate_policy"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Inspect types of spaces"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are four key types of **Gym spaces**:\n",
                "Box, Discrete, Multibinary and MultiDiscrete.\n",
                "\n",
                "There are two **wrapper spaces**, Tuple and Dict that help group different spaces together.\n",
                "\n",
                "These spaces can be used to create simple environment, like the shower environment in the following example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1.1 Define a discrete space\n",
                "disc = Discrete(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "2"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 1.2 Sample the discrete space for a value (between 0 and 2)\n",
                "disc.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Define a box space\n",
                "box = Box(0,1,shape=(3,3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.5333878 , 0.89799386, 0.53723353],\n       [0.8610117 , 0.5875684 , 0.3496501 ],\n       [0.8164015 , 0.5552512 , 0.47559822]], dtype=float32)"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the box space for a value\n",
                "box.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Define a tuple space and combine a discrete and box spaces\n",
                "tup = Tuple((Discrete(2), Box(0,100, shape=(1,))))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(1, array([74.73165], dtype=float32))"
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the tuple space for a value\n",
                "tup.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Define a dict space\n",
                "dic = Dict({'height':Discrete(2), \"speed\":Box(0,100, shape=(1,))}).sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Define a multibinary space\n",
                "multibi = MultiBinary(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 0, 0, 1], dtype=int8)"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the multibinary space for a value\n",
                "multibi.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Define a multidiscrete space\n",
                "multidi = MultiDiscrete([5,2,2])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([4, 1, 0])"
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the multidiscrete space for a value\n",
                "multidi.sample()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Create a custom environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a shower environment class with four key functions\n",
                "class ShowerEnv(Env):\n",
                "\n",
                "    # 1.Define a function to initialize the environment\n",
                "    # environment function\n",
                "    def __init__(self):\n",
                "\n",
                "        # 1.1 Define the discrete action space: \n",
                "        # Actions we can take: down, hold, up\n",
                "        self.action_space = Discrete(3)\n",
                "\n",
                "        # 1.2 Define a temperature range from 0 to 100\n",
                "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
                "\n",
                "        # 1.3 Set initial state: starting temp is 38 +- 3\n",
                "        self.state = 38 + random.randint(-3,3)\n",
                "\n",
                "        # 1.4 Set shower length: set to 60 seconds for testing\n",
                "        # seconds for proper temperature\n",
                "        self.shower_length = 60\n",
                "\n",
                "    # 2.Define the step function for what to do in one action step    \n",
                "    # action function\n",
                "    def step(self, action):\n",
                "        \n",
                "        # 2.1 Apply impact of the action on current state\n",
                "        # 0 -1 = -1 temperature\n",
                "        # 1 -1 = 0 \n",
                "        # 2 -1 = 1 temperature \n",
                "        self.state += action -1 \n",
                "        \n",
                "        # 2.2 Reduce shower length by 1 second at each action\n",
                "        self.shower_length -= 1 \n",
                "        \n",
                "        # 2.3 Calculate reward\n",
                "        # If the temperature is within preferred range, the reward is positive\n",
                "        if self.state \u003e= 37 and self.state \u003c= 39: \n",
                "            reward = 1 \n",
                "        # If the reward is outside of preferred range, the reward is negative \n",
                "        else: \n",
                "            reward = -1 \n",
                "        \n",
                "        # 2.4 Check if shower is done\n",
                "        if self.shower_length \u003c= 0: \n",
                "            done = True\n",
                "        else:\n",
                "            done = False\n",
                "        \n",
                "        # 2.5 Set placeholder for info\n",
                "        info = {}\n",
                "        \n",
                "        # Return step information\n",
                "        return self.state, reward, done, info\n",
                "\n",
                "    # 3.For this lab, we will !!not implement a visualization!! of the environment\n",
                "    def render(self):\n",
                "        # Implement viz\n",
                "        pass\n",
                "    \n",
                "    # 4.Define function to reset the environment for the next run\n",
                "    def reset(self):\n",
                "        # Reset shower temperature to a random value between 35 and 41\n",
                "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
                "        # Reset shower time\n",
                "        self.shower_length = 60 \n",
                "        return self.state"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test the environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
                }
            ],
            "source": [
                "# Initialize the environment\n",
                "env=ShowerEnv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([75.787254], dtype=float32)"
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Write code to sample the environment's observation space\n",
                "env.observation_space.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1"
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Write code to sample the environment's action space\n",
                "env.action_space.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([38.])"
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Reset the environment\n",
                "env.reset()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Episode:1 Score:-6\nEpisode:2 Score:-22\nEpisode:3 Score:-60\nEpisode:4 Score:8\nEpisode:5 Score:-30\n"
                }
            ],
            "source": [
                "# Test five episodes of taking random Actions\n",
                "# in the environment\n",
                "episodes = 5\n",
                "for episode in range(1, episodes+1):\n",
                "    state = env.reset()\n",
                "    done = False\n",
                "    score = 0 \n",
                "    \n",
                "    while not done:\n",
                "        env.render()\n",
                "        action = env.action_space.sample()\n",
                "        n_state, reward, done, info = env.step(action)\n",
                "        score+=reward\n",
                "    print('Episode:{} Score:{}'.format(episode, score))\n",
                "    \n",
                "env.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Earn Your Wings"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Implement the rest of the reinforcement learning algorithm to train the model using MlpPolicy. Save the training in the log_path defined below, and evaluate the model at the end with render set to False. Add comments in your code to explain each step that you take in your implementation.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Using cpu device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\nLogging to ReinforcementLearning/ShowerEnvironment/Training/Logs/PPO_1\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 60       |\n|    ep_rew_mean     | -18.3    |\n| time/              |          |\n|    fps             | 1263     |\n|    iterations      | 1        |\n|    time_elapsed    | 1        |\n|    total_timesteps | 2048     |\n---------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -24.6        |\n| time/                   |              |\n|    fps                  | 1568         |\n|    iterations           | 2            |\n|    time_elapsed         | 2            |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0006628183 |\n|    clip_fraction        | 0.00142      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.1         |\n|    explained_variance   | 2.46e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 27           |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.000545    |\n|    value_loss           | 54.9         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -29.1       |\n| time/                   |             |\n|    fps                  | 1707        |\n|    iterations           | 3           |\n|    time_elapsed         | 3           |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.009497301 |\n|    clip_fraction        | 0.026       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.000287    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.1        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00382    |\n|    value_loss           | 55.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -33.8       |\n| time/                   |             |\n|    fps                  | 1786        |\n|    iterations           | 4           |\n|    time_elapsed         | 4           |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.002655462 |\n|    clip_fraction        | 0.0151      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | -5.17e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.9        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.000185   |\n|    value_loss           | 60.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -32         |\n| time/                   |             |\n|    fps                  | 1837        |\n|    iterations           | 5           |\n|    time_elapsed         | 5           |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008868037 |\n|    clip_fraction        | 0.0213      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | -3.48e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27.6        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -1.44e-05   |\n|    value_loss           | 58.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -30.3       |\n| time/                   |             |\n|    fps                  | 1869        |\n|    iterations           | 6           |\n|    time_elapsed         | 6           |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.009119121 |\n|    clip_fraction        | 0.0659      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 2.16e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.2        |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.00335    |\n|    value_loss           | 64.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -26.1        |\n| time/                   |              |\n|    fps                  | 1888         |\n|    iterations           | 7            |\n|    time_elapsed         | 7            |\n|    total_timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0071813115 |\n|    clip_fraction        | 0.0286       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.07        |\n|    explained_variance   | -7.27e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 31.6         |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.00243     |\n|    value_loss           | 66.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -24.4        |\n| time/                   |              |\n|    fps                  | 1909         |\n|    iterations           | 8            |\n|    time_elapsed         | 8            |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0067445347 |\n|    clip_fraction        | 0.017        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | -3.84e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 36.6         |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00116     |\n|    value_loss           | 71           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -19.7       |\n| time/                   |             |\n|    fps                  | 1926        |\n|    iterations           | 9           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 18432       |\n| train/                  |             |\n|    approx_kl            | 0.013814004 |\n|    clip_fraction        | 0.157       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | -0.00204    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31          |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.0145     |\n|    value_loss           | 63.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -19.9       |\n| time/                   |             |\n|    fps                  | 1940        |\n|    iterations           | 10          |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.004817077 |\n|    clip_fraction        | 0.0473      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | 0.000601    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 34.5        |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.00205    |\n|    value_loss           | 67.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -21.2       |\n| time/                   |             |\n|    fps                  | 1951        |\n|    iterations           | 11          |\n|    time_elapsed         | 11          |\n|    total_timesteps      | 22528       |\n| train/                  |             |\n|    approx_kl            | 0.007842185 |\n|    clip_fraction        | 0.0978      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | -0.00178    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 26.8        |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.00396    |\n|    value_loss           | 57.9        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -20.9        |\n| time/                   |              |\n|    fps                  | 1955         |\n|    iterations           | 12           |\n|    time_elapsed         | 12           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0054496424 |\n|    clip_fraction        | 0.0829       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.05        |\n|    explained_variance   | -0.00026     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 35           |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.00595     |\n|    value_loss           | 65.3         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -15.8       |\n| time/                   |             |\n|    fps                  | 1964        |\n|    iterations           | 13          |\n|    time_elapsed         | 13          |\n|    total_timesteps      | 26624       |\n| train/                  |             |\n|    approx_kl            | 0.013331113 |\n|    clip_fraction        | 0.183       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.05       |\n|    explained_variance   | -0.00108    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.5        |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.0194     |\n|    value_loss           | 59.9        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -12.9        |\n| time/                   |              |\n|    fps                  | 1972         |\n|    iterations           | 14           |\n|    time_elapsed         | 14           |\n|    total_timesteps      | 28672        |\n| train/                  |              |\n|    approx_kl            | 0.0055952845 |\n|    clip_fraction        | 0.0496       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.04        |\n|    explained_variance   | 0.00434      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 27.7         |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.00385     |\n|    value_loss           | 54.1         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -7.74       |\n| time/                   |             |\n|    fps                  | 1979        |\n|    iterations           | 15          |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 30720       |\n| train/                  |             |\n|    approx_kl            | 0.013225562 |\n|    clip_fraction        | 0.199       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.01       |\n|    explained_variance   | -0.0279     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 21.9        |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.0189     |\n|    value_loss           | 44          |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -3.3       |\n| time/                   |            |\n|    fps                  | 1985       |\n|    iterations           | 16         |\n|    time_elapsed         | 16         |\n|    total_timesteps      | 32768      |\n| train/                  |            |\n|    approx_kl            | 0.00841536 |\n|    clip_fraction        | 0.103      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.02      |\n|    explained_variance   | 9.59e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 19.1       |\n|    n_updates            | 150        |\n|    policy_gradient_loss | -0.00785   |\n|    value_loss           | 40.2       |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 3.68         |\n| time/                   |              |\n|    fps                  | 1988         |\n|    iterations           | 17           |\n|    time_elapsed         | 17           |\n|    total_timesteps      | 34816        |\n| train/                  |              |\n|    approx_kl            | 0.0132421255 |\n|    clip_fraction        | 0.23         |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.02        |\n|    explained_variance   | -0.00167     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 13.3         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.0217      |\n|    value_loss           | 28.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 9.86        |\n| time/                   |             |\n|    fps                  | 1992        |\n|    iterations           | 18          |\n|    time_elapsed         | 18          |\n|    total_timesteps      | 36864       |\n| train/                  |             |\n|    approx_kl            | 0.009459869 |\n|    clip_fraction        | 0.145       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.995      |\n|    explained_variance   | 0.000261    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 14.4        |\n|    n_updates            | 170         |\n|    policy_gradient_loss | -0.00678    |\n|    value_loss           | 25.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 15.6        |\n| time/                   |             |\n|    fps                  | 1996        |\n|    iterations           | 19          |\n|    time_elapsed         | 19          |\n|    total_timesteps      | 38912       |\n| train/                  |             |\n|    approx_kl            | 0.008529672 |\n|    clip_fraction        | 0.15        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.988      |\n|    explained_variance   | 3.96e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 17.9        |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.00264    |\n|    value_loss           | 31          |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 22         |\n| time/                   |            |\n|    fps                  | 2000       |\n|    iterations           | 20         |\n|    time_elapsed         | 20         |\n|    total_timesteps      | 40960      |\n| train/                  |            |\n|    approx_kl            | 0.00971166 |\n|    clip_fraction        | 0.167      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.975     |\n|    explained_variance   | 0.000713   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 10.6       |\n|    n_updates            | 190        |\n|    policy_gradient_loss | -0.00695   |\n|    value_loss           | 25.2       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 27.1        |\n| time/                   |             |\n|    fps                  | 2003        |\n|    iterations           | 21          |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 43008       |\n| train/                  |             |\n|    approx_kl            | 0.009010572 |\n|    clip_fraction        | 0.211       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.975      |\n|    explained_variance   | 0.00121     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 13          |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.00448    |\n|    value_loss           | 29.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 29.3        |\n| time/                   |             |\n|    fps                  | 2005        |\n|    iterations           | 22          |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.010548776 |\n|    clip_fraction        | 0.176       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.968      |\n|    explained_variance   | 0.000417    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 20.2        |\n|    n_updates            | 210         |\n|    policy_gradient_loss | 0.00394     |\n|    value_loss           | 33.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 31.6        |\n| time/                   |             |\n|    fps                  | 2008        |\n|    iterations           | 23          |\n|    time_elapsed         | 23          |\n|    total_timesteps      | 47104       |\n| train/                  |             |\n|    approx_kl            | 0.012761099 |\n|    clip_fraction        | 0.226       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.961      |\n|    explained_variance   | -0.000535   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.3        |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.0131     |\n|    value_loss           | 40.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 33.2        |\n| time/                   |             |\n|    fps                  | 2010        |\n|    iterations           | 24          |\n|    time_elapsed         | 24          |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.010403248 |\n|    clip_fraction        | 0.17        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.967      |\n|    explained_variance   | -5.57e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 17.1        |\n|    n_updates            | 230         |\n|    policy_gradient_loss | 0.00254     |\n|    value_loss           | 37.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 36.9        |\n| time/                   |             |\n|    fps                  | 2013        |\n|    iterations           | 25          |\n|    time_elapsed         | 25          |\n|    total_timesteps      | 51200       |\n| train/                  |             |\n|    approx_kl            | 0.010493852 |\n|    clip_fraction        | 0.167       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.973      |\n|    explained_variance   | -1.74e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.4        |\n|    n_updates            | 240         |\n|    policy_gradient_loss | 0.00261     |\n|    value_loss           | 47.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 34.1        |\n| time/                   |             |\n|    fps                  | 2015        |\n|    iterations           | 26          |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 53248       |\n| train/                  |             |\n|    approx_kl            | 0.017444149 |\n|    clip_fraction        | 0.193       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.976      |\n|    explained_variance   | -4.4e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36          |\n|    n_updates            | 250         |\n|    policy_gradient_loss | 0.000292    |\n|    value_loss           | 55.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 30          |\n| time/                   |             |\n|    fps                  | 2017        |\n|    iterations           | 27          |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 55296       |\n| train/                  |             |\n|    approx_kl            | 0.014545645 |\n|    clip_fraction        | 0.214       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.978      |\n|    explained_variance   | -4.21e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 25.9        |\n|    n_updates            | 260         |\n|    policy_gradient_loss | -0.00526    |\n|    value_loss           | 58.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 30.7        |\n| time/                   |             |\n|    fps                  | 2017        |\n|    iterations           | 28          |\n|    time_elapsed         | 28          |\n|    total_timesteps      | 57344       |\n| train/                  |             |\n|    approx_kl            | 0.013871763 |\n|    clip_fraction        | 0.259       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.978      |\n|    explained_variance   | -6.28e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 21.2        |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.0126     |\n|    value_loss           | 52          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 35.3        |\n| time/                   |             |\n|    fps                  | 2017        |\n|    iterations           | 29          |\n|    time_elapsed         | 29          |\n|    total_timesteps      | 59392       |\n| train/                  |             |\n|    approx_kl            | 0.019129757 |\n|    clip_fraction        | 0.273       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.976      |\n|    explained_variance   | -2.87e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.1        |\n|    n_updates            | 280         |\n|    policy_gradient_loss | 0.00288     |\n|    value_loss           | 54.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 42           |\n| time/                   |              |\n|    fps                  | 2018         |\n|    iterations           | 30           |\n|    time_elapsed         | 30           |\n|    total_timesteps      | 61440        |\n| train/                  |              |\n|    approx_kl            | 0.0073479665 |\n|    clip_fraction        | 0.183        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.978       |\n|    explained_variance   | 2.44e-06     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 26.9         |\n|    n_updates            | 290          |\n|    policy_gradient_loss | 0.00796      |\n|    value_loss           | 52           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.2        |\n| time/                   |             |\n|    fps                  | 2020        |\n|    iterations           | 31          |\n|    time_elapsed         | 31          |\n|    total_timesteps      | 63488       |\n| train/                  |             |\n|    approx_kl            | 0.010412514 |\n|    clip_fraction        | 0.22        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.965      |\n|    explained_variance   | 4.17e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.7        |\n|    n_updates            | 300         |\n|    policy_gradient_loss | 0.00471     |\n|    value_loss           | 62.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.9        |\n| time/                   |             |\n|    fps                  | 2018        |\n|    iterations           | 32          |\n|    time_elapsed         | 32          |\n|    total_timesteps      | 65536       |\n| train/                  |             |\n|    approx_kl            | 0.013057632 |\n|    clip_fraction        | 0.222       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.946      |\n|    explained_variance   | 1.29e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.6        |\n|    n_updates            | 310         |\n|    policy_gradient_loss | 0.00437     |\n|    value_loss           | 67.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.4        |\n| time/                   |             |\n|    fps                  | 2018        |\n|    iterations           | 33          |\n|    time_elapsed         | 33          |\n|    total_timesteps      | 67584       |\n| train/                  |             |\n|    approx_kl            | 0.014582647 |\n|    clip_fraction        | 0.196       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.918      |\n|    explained_variance   | -3.46e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 39.2        |\n|    n_updates            | 320         |\n|    policy_gradient_loss | 0.00619     |\n|    value_loss           | 68.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.1        |\n| time/                   |             |\n|    fps                  | 2019        |\n|    iterations           | 34          |\n|    time_elapsed         | 34          |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.017641537 |\n|    clip_fraction        | 0.191       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.911      |\n|    explained_variance   | -2.5e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.7        |\n|    n_updates            | 330         |\n|    policy_gradient_loss | 0.00809     |\n|    value_loss           | 75          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.7        |\n| time/                   |             |\n|    fps                  | 2020        |\n|    iterations           | 35          |\n|    time_elapsed         | 35          |\n|    total_timesteps      | 71680       |\n| train/                  |             |\n|    approx_kl            | 0.012389872 |\n|    clip_fraction        | 0.199       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.898      |\n|    explained_variance   | 5.66e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 37.3        |\n|    n_updates            | 340         |\n|    policy_gradient_loss | 0.00588     |\n|    value_loss           | 80.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 47.6         |\n| time/                   |              |\n|    fps                  | 2022         |\n|    iterations           | 36           |\n|    time_elapsed         | 36           |\n|    total_timesteps      | 73728        |\n| train/                  |              |\n|    approx_kl            | 0.0109063545 |\n|    clip_fraction        | 0.217        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.89        |\n|    explained_variance   | -2.15e-06    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 40.7         |\n|    n_updates            | 350          |\n|    policy_gradient_loss | 0.0108       |\n|    value_loss           | 78.5         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.2        |\n| time/                   |             |\n|    fps                  | 2021        |\n|    iterations           | 37          |\n|    time_elapsed         | 37          |\n|    total_timesteps      | 75776       |\n| train/                  |             |\n|    approx_kl            | 0.010337874 |\n|    clip_fraction        | 0.212       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.906      |\n|    explained_variance   | 1.61e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.4        |\n|    n_updates            | 360         |\n|    policy_gradient_loss | 0.00937     |\n|    value_loss           | 79.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.1        |\n| time/                   |             |\n|    fps                  | 2020        |\n|    iterations           | 38          |\n|    time_elapsed         | 38          |\n|    total_timesteps      | 77824       |\n| train/                  |             |\n|    approx_kl            | 0.025658894 |\n|    clip_fraction        | 0.225       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.893      |\n|    explained_variance   | -9.54e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.5        |\n|    n_updates            | 370         |\n|    policy_gradient_loss | 0.012       |\n|    value_loss           | 83.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.6        |\n| time/                   |             |\n|    fps                  | 2020        |\n|    iterations           | 39          |\n|    time_elapsed         | 39          |\n|    total_timesteps      | 79872       |\n| train/                  |             |\n|    approx_kl            | 0.037335157 |\n|    clip_fraction        | 0.216       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.897      |\n|    explained_variance   | 2.09e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 43.1        |\n|    n_updates            | 380         |\n|    policy_gradient_loss | 0.00947     |\n|    value_loss           | 81.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.2        |\n| time/                   |             |\n|    fps                  | 2021        |\n|    iterations           | 40          |\n|    time_elapsed         | 40          |\n|    total_timesteps      | 81920       |\n| train/                  |             |\n|    approx_kl            | 0.022564206 |\n|    clip_fraction        | 0.254       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.914      |\n|    explained_variance   | 1.73e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 50.7        |\n|    n_updates            | 390         |\n|    policy_gradient_loss | 0.0167      |\n|    value_loss           | 83.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.3        |\n| time/                   |             |\n|    fps                  | 2022        |\n|    iterations           | 41          |\n|    time_elapsed         | 41          |\n|    total_timesteps      | 83968       |\n| train/                  |             |\n|    approx_kl            | 0.023900919 |\n|    clip_fraction        | 0.235       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.929      |\n|    explained_variance   | -2.62e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.7        |\n|    n_updates            | 400         |\n|    policy_gradient_loss | 0.0039      |\n|    value_loss           | 84          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.7        |\n| time/                   |             |\n|    fps                  | 2022        |\n|    iterations           | 42          |\n|    time_elapsed         | 42          |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.027787697 |\n|    clip_fraction        | 0.256       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.934      |\n|    explained_variance   | -3.46e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 26.9        |\n|    n_updates            | 410         |\n|    policy_gradient_loss | 0.0068      |\n|    value_loss           | 76.4        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 46.3       |\n| time/                   |            |\n|    fps                  | 2022       |\n|    iterations           | 43         |\n|    time_elapsed         | 43         |\n|    total_timesteps      | 88064      |\n| train/                  |            |\n|    approx_kl            | 0.01106436 |\n|    clip_fraction        | 0.252      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.912     |\n|    explained_variance   | -1.55e-06  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 37.5       |\n|    n_updates            | 420        |\n|    policy_gradient_loss | 0.0118     |\n|    value_loss           | 79.2       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.2        |\n| time/                   |             |\n|    fps                  | 2024        |\n|    iterations           | 44          |\n|    time_elapsed         | 44          |\n|    total_timesteps      | 90112       |\n| train/                  |             |\n|    approx_kl            | 0.026818741 |\n|    clip_fraction        | 0.268       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.886      |\n|    explained_variance   | -9.54e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.9        |\n|    n_updates            | 430         |\n|    policy_gradient_loss | 0.0112      |\n|    value_loss           | 79          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.1        |\n| time/                   |             |\n|    fps                  | 2025        |\n|    iterations           | 45          |\n|    time_elapsed         | 45          |\n|    total_timesteps      | 92160       |\n| train/                  |             |\n|    approx_kl            | 0.010343919 |\n|    clip_fraction        | 0.261       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.884      |\n|    explained_variance   | 1.79e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.9        |\n|    n_updates            | 440         |\n|    policy_gradient_loss | 0.0155      |\n|    value_loss           | 83.1        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 50.7       |\n| time/                   |            |\n|    fps                  | 2026       |\n|    iterations           | 46         |\n|    time_elapsed         | 46         |\n|    total_timesteps      | 94208      |\n| train/                  |            |\n|    approx_kl            | 0.00903986 |\n|    clip_fraction        | 0.272      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.895     |\n|    explained_variance   | 4.17e-07   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 37.7       |\n|    n_updates            | 450        |\n|    policy_gradient_loss | 0.0148     |\n|    value_loss           | 86.1       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49          |\n| time/                   |             |\n|    fps                  | 2027        |\n|    iterations           | 47          |\n|    time_elapsed         | 47          |\n|    total_timesteps      | 96256       |\n| train/                  |             |\n|    approx_kl            | 0.018054781 |\n|    clip_fraction        | 0.229       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.907      |\n|    explained_variance   | 6.56e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38          |\n|    n_updates            | 460         |\n|    policy_gradient_loss | 0.0112      |\n|    value_loss           | 92.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.2        |\n| time/                   |             |\n|    fps                  | 2027        |\n|    iterations           | 48          |\n|    time_elapsed         | 48          |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.019162444 |\n|    clip_fraction        | 0.224       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.908      |\n|    explained_variance   | 1.07e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60.4        |\n|    n_updates            | 470         |\n|    policy_gradient_loss | 0.0101      |\n|    value_loss           | 86.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.5        |\n| time/                   |             |\n|    fps                  | 2028        |\n|    iterations           | 49          |\n|    time_elapsed         | 49          |\n|    total_timesteps      | 100352      |\n| train/                  |             |\n|    approx_kl            | 0.012556508 |\n|    clip_fraction        | 0.238       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.899      |\n|    explained_variance   | 2.68e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.1        |\n|    n_updates            | 480         |\n|    policy_gradient_loss | 0.011       |\n|    value_loss           | 82          |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 50.2       |\n| time/                   |            |\n|    fps                  | 2029       |\n|    iterations           | 50         |\n|    time_elapsed         | 50         |\n|    total_timesteps      | 102400     |\n| train/                  |            |\n|    approx_kl            | 0.01222463 |\n|    clip_fraction        | 0.236      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.916     |\n|    explained_variance   | 1.07e-06   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 41         |\n|    n_updates            | 490        |\n|    policy_gradient_loss | 0.0126     |\n|    value_loss           | 84         |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.1        |\n| time/                   |             |\n|    fps                  | 2030        |\n|    iterations           | 51          |\n|    time_elapsed         | 51          |\n|    total_timesteps      | 104448      |\n| train/                  |             |\n|    approx_kl            | 0.007481299 |\n|    clip_fraction        | 0.197       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.926      |\n|    explained_variance   | -4.77e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.4        |\n|    n_updates            | 500         |\n|    policy_gradient_loss | 0.00924     |\n|    value_loss           | 90.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.1        |\n| time/                   |             |\n|    fps                  | 2030        |\n|    iterations           | 52          |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 106496      |\n| train/                  |             |\n|    approx_kl            | 0.012238819 |\n|    clip_fraction        | 0.219       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.933      |\n|    explained_variance   | 8.34e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 34.5        |\n|    n_updates            | 510         |\n|    policy_gradient_loss | 0.00874     |\n|    value_loss           | 94.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.4        |\n| time/                   |             |\n|    fps                  | 2027        |\n|    iterations           | 53          |\n|    time_elapsed         | 53          |\n|    total_timesteps      | 108544      |\n| train/                  |             |\n|    approx_kl            | 0.011798529 |\n|    clip_fraction        | 0.23        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.934      |\n|    explained_variance   | 2.98e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 55.7        |\n|    n_updates            | 520         |\n|    policy_gradient_loss | 0.0132      |\n|    value_loss           | 94.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 50.6        |\n| time/                   |             |\n|    fps                  | 2025        |\n|    iterations           | 54          |\n|    time_elapsed         | 54          |\n|    total_timesteps      | 110592      |\n| train/                  |             |\n|    approx_kl            | 0.035336904 |\n|    clip_fraction        | 0.245       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.924      |\n|    explained_variance   | 2.38e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60.2        |\n|    n_updates            | 530         |\n|    policy_gradient_loss | 0.0154      |\n|    value_loss           | 98.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.3        |\n| time/                   |             |\n|    fps                  | 2026        |\n|    iterations           | 55          |\n|    time_elapsed         | 55          |\n|    total_timesteps      | 112640      |\n| train/                  |             |\n|    approx_kl            | 0.012772883 |\n|    clip_fraction        | 0.182       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.935      |\n|    explained_variance   | 5.96e-08    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.3        |\n|    n_updates            | 540         |\n|    policy_gradient_loss | 0.00835     |\n|    value_loss           | 90.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 40.6        |\n| time/                   |             |\n|    fps                  | 2026        |\n|    iterations           | 56          |\n|    time_elapsed         | 56          |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.018739223 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.932      |\n|    explained_variance   | -2.38e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 48.6        |\n|    n_updates            | 550         |\n|    policy_gradient_loss | 0.000932    |\n|    value_loss           | 83.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 35.9        |\n| time/                   |             |\n|    fps                  | 2027        |\n|    iterations           | 57          |\n|    time_elapsed         | 57          |\n|    total_timesteps      | 116736      |\n| train/                  |             |\n|    approx_kl            | 0.013461068 |\n|    clip_fraction        | 0.204       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.917      |\n|    explained_variance   | 6.03e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32.1        |\n|    n_updates            | 560         |\n|    policy_gradient_loss | 0.00815     |\n|    value_loss           | 69.8        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 38.6       |\n| time/                   |            |\n|    fps                  | 2028       |\n|    iterations           | 58         |\n|    time_elapsed         | 58         |\n|    total_timesteps      | 118784     |\n| train/                  |            |\n|    approx_kl            | 0.01865885 |\n|    clip_fraction        | 0.253      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.908     |\n|    explained_variance   | 0.000144   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 22.9       |\n|    n_updates            | 570        |\n|    policy_gradient_loss | 0.00757    |\n|    value_loss           | 60.2       |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 42.9       |\n| time/                   |            |\n|    fps                  | 2028       |\n|    iterations           | 59         |\n|    time_elapsed         | 59         |\n|    total_timesteps      | 120832     |\n| train/                  |            |\n|    approx_kl            | 0.09923614 |\n|    clip_fraction        | 0.279      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.906     |\n|    explained_variance   | 4.51e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 31.7       |\n|    n_updates            | 580        |\n|    policy_gradient_loss | 0.0191     |\n|    value_loss           | 61.3       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.4        |\n| time/                   |             |\n|    fps                  | 2028        |\n|    iterations           | 60          |\n|    time_elapsed         | 60          |\n|    total_timesteps      | 122880      |\n| train/                  |             |\n|    approx_kl            | 0.027740266 |\n|    clip_fraction        | 0.211       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.914      |\n|    explained_variance   | 8.63e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.2        |\n|    n_updates            | 590         |\n|    policy_gradient_loss | 0.0117      |\n|    value_loss           | 73.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.9        |\n| time/                   |             |\n|    fps                  | 2029        |\n|    iterations           | 61          |\n|    time_elapsed         | 61          |\n|    total_timesteps      | 124928      |\n| train/                  |             |\n|    approx_kl            | 0.012164213 |\n|    clip_fraction        | 0.305       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.907      |\n|    explained_variance   | 3.9e-05     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.6        |\n|    n_updates            | 600         |\n|    policy_gradient_loss | 0.0192      |\n|    value_loss           | 79.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 44.1        |\n| time/                   |             |\n|    fps                  | 2030        |\n|    iterations           | 62          |\n|    time_elapsed         | 62          |\n|    total_timesteps      | 126976      |\n| train/                  |             |\n|    approx_kl            | 0.010768536 |\n|    clip_fraction        | 0.228       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.899      |\n|    explained_variance   | 0.000127    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.9        |\n|    n_updates            | 610         |\n|    policy_gradient_loss | 0.00809     |\n|    value_loss           | 81.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 38.3        |\n| time/                   |             |\n|    fps                  | 2030        |\n|    iterations           | 63          |\n|    time_elapsed         | 63          |\n|    total_timesteps      | 129024      |\n| train/                  |             |\n|    approx_kl            | 0.014822215 |\n|    clip_fraction        | 0.262       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.91       |\n|    explained_variance   | 7.39e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.3        |\n|    n_updates            | 620         |\n|    policy_gradient_loss | 0.0105      |\n|    value_loss           | 69.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 34          |\n| time/                   |             |\n|    fps                  | 2030        |\n|    iterations           | 64          |\n|    time_elapsed         | 64          |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.013377511 |\n|    clip_fraction        | 0.265       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.906      |\n|    explained_variance   | 0.000242    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.7        |\n|    n_updates            | 630         |\n|    policy_gradient_loss | 0.0078      |\n|    value_loss           | 61.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 36.9         |\n| time/                   |              |\n|    fps                  | 2031         |\n|    iterations           | 65           |\n|    time_elapsed         | 65           |\n|    total_timesteps      | 133120       |\n| train/                  |              |\n|    approx_kl            | 0.0124127725 |\n|    clip_fraction        | 0.229        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.913       |\n|    explained_variance   | 0.000423     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 26.3         |\n|    n_updates            | 640          |\n|    policy_gradient_loss | 0.000748     |\n|    value_loss           | 57.5         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 38.8         |\n| time/                   |              |\n|    fps                  | 2031         |\n|    iterations           | 66           |\n|    time_elapsed         | 66           |\n|    total_timesteps      | 135168       |\n| train/                  |              |\n|    approx_kl            | 0.0139276255 |\n|    clip_fraction        | 0.244        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.906       |\n|    explained_variance   | 0.000539     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 25.6         |\n|    n_updates            | 650          |\n|    policy_gradient_loss | 0.00436      |\n|    value_loss           | 60.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.9        |\n| time/                   |             |\n|    fps                  | 2032        |\n|    iterations           | 67          |\n|    time_elapsed         | 67          |\n|    total_timesteps      | 137216      |\n| train/                  |             |\n|    approx_kl            | 0.022163285 |\n|    clip_fraction        | 0.227       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.906      |\n|    explained_variance   | 0.000427    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 29.1        |\n|    n_updates            | 660         |\n|    policy_gradient_loss | 0.00326     |\n|    value_loss           | 57.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 44.4        |\n| time/                   |             |\n|    fps                  | 2033        |\n|    iterations           | 68          |\n|    time_elapsed         | 68          |\n|    total_timesteps      | 139264      |\n| train/                  |             |\n|    approx_kl            | 0.014570974 |\n|    clip_fraction        | 0.273       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.908      |\n|    explained_variance   | 0.000354    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.4        |\n|    n_updates            | 670         |\n|    policy_gradient_loss | 0.0152      |\n|    value_loss           | 65.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.9        |\n| time/                   |             |\n|    fps                  | 2033        |\n|    iterations           | 69          |\n|    time_elapsed         | 69          |\n|    total_timesteps      | 141312      |\n| train/                  |             |\n|    approx_kl            | 0.015977154 |\n|    clip_fraction        | 0.208       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.915      |\n|    explained_variance   | 0.000306    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47          |\n|    n_updates            | 680         |\n|    policy_gradient_loss | 0.00828     |\n|    value_loss           | 76.1        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 45.4       |\n| time/                   |            |\n|    fps                  | 2033       |\n|    iterations           | 70         |\n|    time_elapsed         | 70         |\n|    total_timesteps      | 143360     |\n| train/                  |            |\n|    approx_kl            | 0.01682543 |\n|    clip_fraction        | 0.241      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.909     |\n|    explained_variance   | 0.000225   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 42.1       |\n|    n_updates            | 690        |\n|    policy_gradient_loss | 0.00734    |\n|    value_loss           | 75.1       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.2        |\n| time/                   |             |\n|    fps                  | 2034        |\n|    iterations           | 71          |\n|    time_elapsed         | 71          |\n|    total_timesteps      | 145408      |\n| train/                  |             |\n|    approx_kl            | 0.013338349 |\n|    clip_fraction        | 0.201       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.909      |\n|    explained_variance   | 0.000301    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.3        |\n|    n_updates            | 700         |\n|    policy_gradient_loss | 0.00465     |\n|    value_loss           | 78.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48          |\n| time/                   |             |\n|    fps                  | 2034        |\n|    iterations           | 72          |\n|    time_elapsed         | 72          |\n|    total_timesteps      | 147456      |\n| train/                  |             |\n|    approx_kl            | 0.009202326 |\n|    clip_fraction        | 0.25        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.894      |\n|    explained_variance   | 0.000157    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.6        |\n|    n_updates            | 710         |\n|    policy_gradient_loss | 0.0146      |\n|    value_loss           | 77.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.4        |\n| time/                   |             |\n|    fps                  | 2035        |\n|    iterations           | 73          |\n|    time_elapsed         | 73          |\n|    total_timesteps      | 149504      |\n| train/                  |             |\n|    approx_kl            | 0.011255875 |\n|    clip_fraction        | 0.24        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.89       |\n|    explained_variance   | 0.000162    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.8        |\n|    n_updates            | 720         |\n|    policy_gradient_loss | 0.0136      |\n|    value_loss           | 80.7        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 49         |\n| time/                   |            |\n|    fps                  | 2035       |\n|    iterations           | 74         |\n|    time_elapsed         | 74         |\n|    total_timesteps      | 151552     |\n| train/                  |            |\n|    approx_kl            | 0.02485125 |\n|    clip_fraction        | 0.26       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.878     |\n|    explained_variance   | 0.00018    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 45.8       |\n|    n_updates            | 730        |\n|    policy_gradient_loss | 0.0173     |\n|    value_loss           | 87.9       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 50.5        |\n| time/                   |             |\n|    fps                  | 2035        |\n|    iterations           | 75          |\n|    time_elapsed         | 75          |\n|    total_timesteps      | 153600      |\n| train/                  |             |\n|    approx_kl            | 0.067610785 |\n|    clip_fraction        | 0.253       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.853      |\n|    explained_variance   | 4.45e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 57.6        |\n|    n_updates            | 740         |\n|    policy_gradient_loss | 0.0146      |\n|    value_loss           | 89.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.1        |\n| time/                   |             |\n|    fps                  | 2035        |\n|    iterations           | 76          |\n|    time_elapsed         | 76          |\n|    total_timesteps      | 155648      |\n| train/                  |             |\n|    approx_kl            | 0.013760079 |\n|    clip_fraction        | 0.242       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.861      |\n|    explained_variance   | 1.26e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.9        |\n|    n_updates            | 750         |\n|    policy_gradient_loss | 0.0159      |\n|    value_loss           | 91.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.1        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 77          |\n|    time_elapsed         | 77          |\n|    total_timesteps      | 157696      |\n| train/                  |             |\n|    approx_kl            | 0.042472035 |\n|    clip_fraction        | 0.23        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.855      |\n|    explained_variance   | 2.92e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 43.4        |\n|    n_updates            | 760         |\n|    policy_gradient_loss | 0.018       |\n|    value_loss           | 88.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.3        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 78          |\n|    time_elapsed         | 78          |\n|    total_timesteps      | 159744      |\n| train/                  |             |\n|    approx_kl            | 0.013022423 |\n|    clip_fraction        | 0.188       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.847      |\n|    explained_variance   | 2.38e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 37.2        |\n|    n_updates            | 770         |\n|    policy_gradient_loss | 0.00597     |\n|    value_loss           | 82.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 44.9        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 79          |\n|    time_elapsed         | 79          |\n|    total_timesteps      | 161792      |\n| train/                  |             |\n|    approx_kl            | 0.010308953 |\n|    clip_fraction        | 0.175       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.828      |\n|    explained_variance   | 0.000216    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.2        |\n|    n_updates            | 780         |\n|    policy_gradient_loss | 0.0073      |\n|    value_loss           | 80.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 41.2        |\n| time/                   |             |\n|    fps                  | 2035        |\n|    iterations           | 80          |\n|    time_elapsed         | 80          |\n|    total_timesteps      | 163840      |\n| train/                  |             |\n|    approx_kl            | 0.026877273 |\n|    clip_fraction        | 0.169       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.809      |\n|    explained_variance   | 0.000466    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38          |\n|    n_updates            | 790         |\n|    policy_gradient_loss | 0.00659     |\n|    value_loss           | 83.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 36.8        |\n| time/                   |             |\n|    fps                  | 2035        |\n|    iterations           | 81          |\n|    time_elapsed         | 81          |\n|    total_timesteps      | 165888      |\n| train/                  |             |\n|    approx_kl            | 0.034236066 |\n|    clip_fraction        | 0.203       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.776      |\n|    explained_variance   | 0.000635    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.1        |\n|    n_updates            | 800         |\n|    policy_gradient_loss | 0.00362     |\n|    value_loss           | 76.1        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 34.1       |\n| time/                   |            |\n|    fps                  | 2035       |\n|    iterations           | 82         |\n|    time_elapsed         | 82         |\n|    total_timesteps      | 167936     |\n| train/                  |            |\n|    approx_kl            | 0.01962726 |\n|    clip_fraction        | 0.219      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.754     |\n|    explained_variance   | 0.00174    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 47.2       |\n|    n_updates            | 810        |\n|    policy_gradient_loss | -0.00581   |\n|    value_loss           | 77.9       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 37.1        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 83          |\n|    time_elapsed         | 83          |\n|    total_timesteps      | 169984      |\n| train/                  |             |\n|    approx_kl            | 0.021058913 |\n|    clip_fraction        | 0.209       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.742      |\n|    explained_variance   | 0.00187     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27          |\n|    n_updates            | 820         |\n|    policy_gradient_loss | -0.000191   |\n|    value_loss           | 65.6        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 46.3       |\n| time/                   |            |\n|    fps                  | 2036       |\n|    iterations           | 84         |\n|    time_elapsed         | 84         |\n|    total_timesteps      | 172032     |\n| train/                  |            |\n|    approx_kl            | 0.03153781 |\n|    clip_fraction        | 0.182      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.719     |\n|    explained_variance   | 0.000866   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 42.1       |\n|    n_updates            | 830        |\n|    policy_gradient_loss | 0.00911    |\n|    value_loss           | 57.3       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.6        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 85          |\n|    time_elapsed         | 85          |\n|    total_timesteps      | 174080      |\n| train/                  |             |\n|    approx_kl            | 0.028140668 |\n|    clip_fraction        | 0.213       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.722      |\n|    explained_variance   | 0.000219    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.6        |\n|    n_updates            | 840         |\n|    policy_gradient_loss | 0.02        |\n|    value_loss           | 76.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 55           |\n| time/                   |              |\n|    fps                  | 2036         |\n|    iterations           | 86           |\n|    time_elapsed         | 86           |\n|    total_timesteps      | 176128       |\n| train/                  |              |\n|    approx_kl            | 0.0052933944 |\n|    clip_fraction        | 0.161        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.704       |\n|    explained_variance   | -9.42e-06    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 41.4         |\n|    n_updates            | 850          |\n|    policy_gradient_loss | 0.0126       |\n|    value_loss           | 89.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 52.3         |\n| time/                   |              |\n|    fps                  | 2037         |\n|    iterations           | 87           |\n|    time_elapsed         | 87           |\n|    total_timesteps      | 178176       |\n| train/                  |              |\n|    approx_kl            | 0.0049466463 |\n|    clip_fraction        | 0.172        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.718       |\n|    explained_variance   | 2.24e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 41.1         |\n|    n_updates            | 860          |\n|    policy_gradient_loss | 0.0123       |\n|    value_loss           | 95.3         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 50.4        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 88          |\n|    time_elapsed         | 88          |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.005324931 |\n|    clip_fraction        | 0.148       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.737      |\n|    explained_variance   | 9.66e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 52.5        |\n|    n_updates            | 870         |\n|    policy_gradient_loss | 0.00914     |\n|    value_loss           | 92.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.9        |\n| time/                   |             |\n|    fps                  | 2038        |\n|    iterations           | 89          |\n|    time_elapsed         | 89          |\n|    total_timesteps      | 182272      |\n| train/                  |             |\n|    approx_kl            | 0.018172625 |\n|    clip_fraction        | 0.199       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.746      |\n|    explained_variance   | 2.77e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.8        |\n|    n_updates            | 880         |\n|    policy_gradient_loss | 0.0122      |\n|    value_loss           | 95          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.8        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 90          |\n|    time_elapsed         | 90          |\n|    total_timesteps      | 184320      |\n| train/                  |             |\n|    approx_kl            | 0.010405606 |\n|    clip_fraction        | 0.179       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.739      |\n|    explained_variance   | 3.18e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 37.8        |\n|    n_updates            | 890         |\n|    policy_gradient_loss | 0.00412     |\n|    value_loss           | 95.5        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 50         |\n| time/                   |            |\n|    fps                  | 2036       |\n|    iterations           | 91         |\n|    time_elapsed         | 91         |\n|    total_timesteps      | 186368     |\n| train/                  |            |\n|    approx_kl            | 0.03757547 |\n|    clip_fraction        | 0.204      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.753     |\n|    explained_variance   | 1.47e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 58.6       |\n|    n_updates            | 900        |\n|    policy_gradient_loss | 0.0144     |\n|    value_loss           | 92.7       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 50.2        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 92          |\n|    time_elapsed         | 92          |\n|    total_timesteps      | 188416      |\n| train/                  |             |\n|    approx_kl            | 0.009793609 |\n|    clip_fraction        | 0.174       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.771      |\n|    explained_variance   | 5.28e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60          |\n|    n_updates            | 910         |\n|    policy_gradient_loss | 0.00732     |\n|    value_loss           | 94.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 47.1         |\n| time/                   |              |\n|    fps                  | 2036         |\n|    iterations           | 93           |\n|    time_elapsed         | 93           |\n|    total_timesteps      | 190464       |\n| train/                  |              |\n|    approx_kl            | 0.0054219156 |\n|    clip_fraction        | 0.15         |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.738       |\n|    explained_variance   | 2.6e-05      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 47.6         |\n|    n_updates            | 920          |\n|    policy_gradient_loss | 0.00944      |\n|    value_loss           | 91.2         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.1        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 94          |\n|    time_elapsed         | 94          |\n|    total_timesteps      | 192512      |\n| train/                  |             |\n|    approx_kl            | 0.011660326 |\n|    clip_fraction        | 0.147       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.742      |\n|    explained_variance   | 5.75e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 50.8        |\n|    n_updates            | 930         |\n|    policy_gradient_loss | -0.0015     |\n|    value_loss           | 91.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 44.7         |\n| time/                   |              |\n|    fps                  | 2036         |\n|    iterations           | 95           |\n|    time_elapsed         | 95           |\n|    total_timesteps      | 194560       |\n| train/                  |              |\n|    approx_kl            | 0.0082778605 |\n|    clip_fraction        | 0.153        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.73        |\n|    explained_variance   | -7.67e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 29.8         |\n|    n_updates            | 940          |\n|    policy_gradient_loss | 0.00424      |\n|    value_loss           | 84.8         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.4        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 96          |\n|    time_elapsed         | 96          |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.014295459 |\n|    clip_fraction        | 0.156       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.747      |\n|    explained_variance   | 3.87e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.7        |\n|    n_updates            | 950         |\n|    policy_gradient_loss | 0.00313     |\n|    value_loss           | 84.8        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 47.8         |\n| time/                   |              |\n|    fps                  | 2037         |\n|    iterations           | 97           |\n|    time_elapsed         | 97           |\n|    total_timesteps      | 198656       |\n| train/                  |              |\n|    approx_kl            | 0.0059298314 |\n|    clip_fraction        | 0.161        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.742       |\n|    explained_variance   | 7.19e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 39.6         |\n|    n_updates            | 960          |\n|    policy_gradient_loss | 0.00895      |\n|    value_loss           | 82.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 50.8         |\n| time/                   |              |\n|    fps                  | 2036         |\n|    iterations           | 98           |\n|    time_elapsed         | 98           |\n|    total_timesteps      | 200704       |\n| train/                  |              |\n|    approx_kl            | 0.0110173365 |\n|    clip_fraction        | 0.195        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.744       |\n|    explained_variance   | 9.12e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 50.2         |\n|    n_updates            | 970          |\n|    policy_gradient_loss | 0.0119       |\n|    value_loss           | 86.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 55.2         |\n| time/                   |              |\n|    fps                  | 2037         |\n|    iterations           | 99           |\n|    time_elapsed         | 99           |\n|    total_timesteps      | 202752       |\n| train/                  |              |\n|    approx_kl            | 0.0054026563 |\n|    clip_fraction        | 0.213        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.723       |\n|    explained_variance   | 4.81e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 39.9         |\n|    n_updates            | 980          |\n|    policy_gradient_loss | 0.0182       |\n|    value_loss           | 95.6         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 57.1        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 100         |\n|    time_elapsed         | 100         |\n|    total_timesteps      | 204800      |\n| train/                  |             |\n|    approx_kl            | 0.008385034 |\n|    clip_fraction        | 0.166       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.705      |\n|    explained_variance   | 1.73e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 57.7        |\n|    n_updates            | 990         |\n|    policy_gradient_loss | 0.0131      |\n|    value_loss           | 103         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 57          |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 101         |\n|    time_elapsed         | 101         |\n|    total_timesteps      | 206848      |\n| train/                  |             |\n|    approx_kl            | 0.007627325 |\n|    clip_fraction        | 0.191       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.703      |\n|    explained_variance   | 3.46e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 49.8        |\n|    n_updates            | 1000        |\n|    policy_gradient_loss | 0.0149      |\n|    value_loss           | 108         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 57          |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 102         |\n|    time_elapsed         | 102         |\n|    total_timesteps      | 208896      |\n| train/                  |             |\n|    approx_kl            | 0.018813554 |\n|    clip_fraction        | 0.164       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.728      |\n|    explained_variance   | 1.79e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 55.4        |\n|    n_updates            | 1010        |\n|    policy_gradient_loss | 0.0112      |\n|    value_loss           | 109         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 57          |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 103         |\n|    time_elapsed         | 103         |\n|    total_timesteps      | 210944      |\n| train/                  |             |\n|    approx_kl            | 0.013174059 |\n|    clip_fraction        | 0.2         |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.725      |\n|    explained_variance   | 8.94e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.8        |\n|    n_updates            | 1020        |\n|    policy_gradient_loss | 0.0184      |\n|    value_loss           | 113         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 51.8       |\n| time/                   |            |\n|    fps                  | 2037       |\n|    iterations           | 104        |\n|    time_elapsed         | 104        |\n|    total_timesteps      | 212992     |\n| train/                  |            |\n|    approx_kl            | 0.08918023 |\n|    clip_fraction        | 0.19       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.743     |\n|    explained_variance   | -1.07e-06  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 55.4       |\n|    n_updates            | 1030       |\n|    policy_gradient_loss | 0.0171     |\n|    value_loss           | 114        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.9        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 105         |\n|    time_elapsed         | 105         |\n|    total_timesteps      | 215040      |\n| train/                  |             |\n|    approx_kl            | 0.010209881 |\n|    clip_fraction        | 0.193       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.739      |\n|    explained_variance   | 1.18e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.3        |\n|    n_updates            | 1040        |\n|    policy_gradient_loss | 0.00426     |\n|    value_loss           | 108         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 41.1        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 106         |\n|    time_elapsed         | 106         |\n|    total_timesteps      | 217088      |\n| train/                  |             |\n|    approx_kl            | 0.017036181 |\n|    clip_fraction        | 0.237       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.732      |\n|    explained_variance   | 4.32e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 59.7        |\n|    n_updates            | 1050        |\n|    policy_gradient_loss | 0.0131      |\n|    value_loss           | 90.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 44.9        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 107         |\n|    time_elapsed         | 107         |\n|    total_timesteps      | 219136      |\n| train/                  |             |\n|    approx_kl            | 0.010772616 |\n|    clip_fraction        | 0.193       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.712      |\n|    explained_variance   | 0.000464    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 29.9        |\n|    n_updates            | 1060        |\n|    policy_gradient_loss | 0.00449     |\n|    value_loss           | 84.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.4        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 108         |\n|    time_elapsed         | 108         |\n|    total_timesteps      | 221184      |\n| train/                  |             |\n|    approx_kl            | 0.043390468 |\n|    clip_fraction        | 0.266       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.739      |\n|    explained_variance   | 0.000732    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 61.7        |\n|    n_updates            | 1070        |\n|    policy_gradient_loss | 0.0186      |\n|    value_loss           | 85.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 53.8        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 109         |\n|    time_elapsed         | 109         |\n|    total_timesteps      | 223232      |\n| train/                  |             |\n|    approx_kl            | 0.012679474 |\n|    clip_fraction        | 0.171       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.742      |\n|    explained_variance   | 0.000119    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.3        |\n|    n_updates            | 1080        |\n|    policy_gradient_loss | 0.0145      |\n|    value_loss           | 90.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 53.6        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 110         |\n|    time_elapsed         | 110         |\n|    total_timesteps      | 225280      |\n| train/                  |             |\n|    approx_kl            | 0.021632198 |\n|    clip_fraction        | 0.204       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.749      |\n|    explained_variance   | 2.32e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.3        |\n|    n_updates            | 1090        |\n|    policy_gradient_loss | 0.016       |\n|    value_loss           | 97.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.1        |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 111         |\n|    time_elapsed         | 111         |\n|    total_timesteps      | 227328      |\n| train/                  |             |\n|    approx_kl            | 0.027718129 |\n|    clip_fraction        | 0.233       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.74       |\n|    explained_variance   | 0.000177    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 46          |\n|    n_updates            | 1100        |\n|    policy_gradient_loss | 0.0144      |\n|    value_loss           | 99.6        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 45.6         |\n| time/                   |              |\n|    fps                  | 2038         |\n|    iterations           | 112          |\n|    time_elapsed         | 112          |\n|    total_timesteps      | 229376       |\n| train/                  |              |\n|    approx_kl            | 0.0122075435 |\n|    clip_fraction        | 0.152        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.715       |\n|    explained_variance   | 0.000224     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 38.9         |\n|    n_updates            | 1110         |\n|    policy_gradient_loss | 0.00393      |\n|    value_loss           | 85.5         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.1        |\n| time/                   |             |\n|    fps                  | 2038        |\n|    iterations           | 113         |\n|    time_elapsed         | 113         |\n|    total_timesteps      | 231424      |\n| train/                  |             |\n|    approx_kl            | 0.029789448 |\n|    clip_fraction        | 0.172       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.736      |\n|    explained_variance   | 0.000947    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41          |\n|    n_updates            | 1120        |\n|    policy_gradient_loss | 0.0111      |\n|    value_loss           | 82.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.3        |\n| time/                   |             |\n|    fps                  | 2038        |\n|    iterations           | 114         |\n|    time_elapsed         | 114         |\n|    total_timesteps      | 233472      |\n| train/                  |             |\n|    approx_kl            | 0.021869687 |\n|    clip_fraction        | 0.195       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.735      |\n|    explained_var\n[too much output ...]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n  warnings.warn(\n"
                },
                {
                    "data": {
                        "text/plain": "(59.4, 0.9165151389911679)"
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Define a path for where to output the training log files\n",
                "log_path = os.path.join('ReinforcementLearning/ShowerEnvironment/Training', 'Logs')\n",
                "#build the model\n",
                "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
                "#start training\n",
                "model.learn(total_timesteps=400000)\n",
                "#save the training\n",
                "model.save('PPO')\n",
                "#evaluate \n",
                "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
            ]
        }
    ]
}
